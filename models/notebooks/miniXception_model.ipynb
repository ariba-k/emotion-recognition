{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n", "from tensorflow.keras.layers import Activation, Conv2D, BatchNormalization, GlobalAveragePooling2D\n", "from tensorflow.keras.layers import Input, MaxPooling2D, SeparableConv2D\n", "from tensorflow.keras.models import Model\n", "from tensorflow.keras import layers\n", "from tensorflow.keras.regularizers import l2\n", "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n", "import os\n", "import pandas as pd"]}, {"cell_type": "markdown", "metadata": {}, "source": ["https://github.com/kumarnikhil936/face_emotion_recognition_cnn<br>\n", "https://github.com/XiuweiHe/EmotionClassifier/blob/master/src/cnn.py --> consider doing a tiny ALEXNET"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_dir = './data/train'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_datagen = ImageDataGenerator(rescale=1. / 255,\n", "                                   validation_split=0.2,\n", "                                   rotation_range=5,\n", "                                   width_shift_range=0.2,\n", "                                   height_shift_range=0.2,\n", "                                   shear_range=0.2,\n", "                                   horizontal_flip=True,\n", "                                   vertical_flip=True,\n", "                                   fill_mode='nearest')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["valid_datagen = ImageDataGenerator(rescale=1. / 255,\n", "                                   validation_split=0.2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_dataset = train_datagen.flow_from_directory(directory=train_dir,\n", "                                                  target_size=(48, 48),\n", "                                                  class_mode='categorical',\n", "                                                  subset='training',\n", "                                                  batch_size=64)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["valid_dataset = valid_datagen.flow_from_directory(directory=train_dir,\n", "                                                  target_size=(48, 48),\n", "                                                  class_mode='categorical',\n", "                                                  subset='validation',\n", "                                                  batch_size=64)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["image_shape = (48, 48, 3)\n", "num_classes = 7\n", "epochs = 50\n", "lr = 1e-10\n", "regularization = l2(0.01)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["image_input = Input(image_shape)\n", "x = Conv2D(filters=8, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(\n", "    image_input)\n", "x = BatchNormalization()(x)\n", "x = Activation('relu')(x)\n", "x = Conv2D(filters=8, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(x)\n", "x = BatchNormalization()(x)\n", "x = Activation('relu')(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["module 1<br>\n", "residual module"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["residual = Conv2D(filters=16, kernel_size=(1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n", "residual = BatchNormalization()(residual)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x = SeparableConv2D(filters=16, kernel_size=(3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(\n", "    x)\n", "x = BatchNormalization()(x)\n", "x = Activation('relu')(x)\n", "x = SeparableConv2D(filters=16, kernel_size=(3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(\n", "    x)\n", "x = BatchNormalization()(x)\n", "x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n", "x = layers.add([x, residual])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["module 2<br>\n", "residual module"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["residual = Conv2D(filters=32, kernel_size=(1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n", "residual = BatchNormalization()(residual)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x = SeparableConv2D(filters=32, kernel_size=(3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(\n", "    x)\n", "x = BatchNormalization()(x)\n", "x = Activation('relu')(x)\n", "x = SeparableConv2D(filters=32, kernel_size=(3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(\n", "    x)\n", "x = BatchNormalization()(x)\n", "x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n", "x = layers.add([x, residual])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["module 3<br>\n", "residual module"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["residual = Conv2D(filters=64, kernel_size=(1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n", "residual = BatchNormalization()(residual)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x = SeparableConv2D(filters=64, kernel_size=(3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(\n", "    x)\n", "x = BatchNormalization()(x)\n", "x = Activation('relu')(x)\n", "x = SeparableConv2D(filters=64, kernel_size=(3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(\n", "    x)\n", "x = BatchNormalization()(x)\n", "x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n", "x = layers.add([x, residual])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["module 4<br>\n", "residual module"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["residual = Conv2D(filters=128, kernel_size=(1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n", "residual = BatchNormalization()(residual)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x = SeparableConv2D(filters=128, kernel_size=(3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(\n", "    x)\n", "x = BatchNormalization()(x)\n", "x = Activation('relu')(x)\n", "x = SeparableConv2D(filters=128, kernel_size=(3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(\n", "    x)\n", "x = BatchNormalization()(x)\n", "x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n", "x = layers.add([x, residual])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x = Conv2D(filters=num_classes, kernel_size=(3, 3), padding='same')(x)\n", "x = GlobalAveragePooling2D()(x)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["output = Activation('softmax', name='predictions')(x)\n", "model = Model(image_input, output)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.summary()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lrd = ReduceLROnPlateau(monitor='val_loss', patience=20, verbose=1, factor=0.50, min_lr=lr)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mcp = ModelCheckpoint('./weights/miniXception_model.h5', monitor='val_accuracy',\n", "                      mode='max',\n", "                      save_best_only=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["es = EarlyStopping(verbose=1, patience=20)\n", "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n", "history = model.fit(train_dataset, validation_data=valid_dataset, epochs=epochs,\n", "                    verbose=1, callbacks=[lrd, mcp, es])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["os.makedirs('./history', exist_ok=True)\n", "file_name = './history/miniXception_hist.csv'\n", "with open(file_name, mode='w') as f:\n", "    pd.DataFrame(history.history).to_csv(f)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}